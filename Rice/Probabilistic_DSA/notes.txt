OK. Why? This is an active area of a search people look at like the heat signature. Or there are physics. Physics of the world might have some atom less. Generating a truly random number is hard. In computer science we cannot do that. So what we do is. This is where the word pseudorandomness comes in. Pseudorandomness is a way to simulate the effect of our animals. So there are certain algorithms and certain ways in which you can generate random numbers that appears to be random, but they are not random, they are pseudorandom. Now one of the biggest thing about how to check whether what is pseudorandom or not, have you seen how many of you have played with the random number generator or used random number generator? If not, I invite you to use Python or something. Use a random generator. One thing you can do is set the seed. If you set a seed, it always generates the same random. So for example, if I ask if I'm writing this program of flipping a coin. Heads, tails, head tails. If I set the seat to be 45, it will always generate the same sequence. And that means it is not random anymore. It is an illusion of randomness. And we'll look into some of those. Again, the goal is not to dive into those algorithms. I just want everybody here to be aware of where these things come from, and then we'll be using a lot of things. So obviously where does the random number comes from? As natural experiments? Some physical phenomena like weather, right? If it rains one. If it does not rain zero, right? Some distribution. But we do not have the capabilities to do physical experiments in computers. So we use a pseudorandom generator which is seed based and it is deterministic. Look at the irony of things, it is not random. It is not. There is nothing random. In the moment you give me a seed, it is deterministic. Determinism is useful. We'll talk about how that works. In fact universal hashing the way we will see that there are also going to be A lot of interesting and so. Far. But it's still base and it will be deterministic and will give the exact same sequence if the CDC like your animal. Again, how are these numbers generated? Well, there are some classical ideas that dating back to 1949. So there are some of these algorithms finally derived from number K2. And basically we use that to generate a hand. So as you can see everything starts with a CD. So let us say I start with the CD 1111. There is a method called middle square method in which what you do is you square it. And you create a two end digit out of end digit. So you start with an end digit number, which is your seed. When you square it, it will be two integers roughly. Sometimes it won't be less than 2M, but generally you square it. It will be 21 digit if it's not even always at zero, and one OK. So you generate a 2 N digit number and you then report the middle N number as the next term. You start with 1111. You sweat it, you get 1234321. That's not eight digits, that's only seven digits. So let's make it 8 digits by adding zero in front of it, and then take the middle four digits. So 2343 is the middle four digit. That's fine. And then what is going to be my next summer going to get squatters and do the same, that's my next. So that is how you generate a sequence of that numbers and why this will work. Is because it's known that when you square a number, their bits mix in a certain way. Again, like it's not in a random way, you exactly know how the bits change, it's a square N. So if you square a binary number, look at the binary representation of how a bit makes. But you can argue that if you keep doing this enough, the distribution of your numbers that you will see the distribution of the four digits number that you are generating will be more of a single. Basically can prove using number theoretical. So this is. But then again as you can see there are, you know some of the issues here. There needs to be even the end grid number and needs to be given if you do odd digits on your edge cases. So there are issues with that. Again, another idea is using what we call whale sequence. So you basically if you look at the sequence of all multiples of an integer, there is a how many of. You have some experience with number theory? Like, odd, even like. Yeah. So basically there are these modular if you have seen this module. Mathematicians like break their heads for like decades of what these audio arithmetic can do. And one of the interesting results in this modular arithmetic is when you take something modulo of prime number. Then zero to P -, 1 the results of if you mod something with prime P where T is a prime number. So for example you have a number N and you are looking at something like N mod B. Everybody knows the modification, right? This is actually a number between zero to P -. And generally if N is relatively prime to P and you generate a lot of N, then this is kind of uniformly. Between zero would be nice. So what you do is you start with K. You make 2K4K3K, 4K sort of stuff. Make sure K is relatively P so K is not a multiple of P or something like that. That's easy. And what you will see is that if you do this, then mod B is uniformly distributed between zero to P - 1. Obviously now only generating zero to T - 1. So if somebody tells me 100, well 100 -, of 99 is one point which is 101 and then you know there are ways to constrain some of the, but this is some of the. Nicer way of. Generating. But we need not be prime. We need to be relatively prime. So these are some of the ideas in which you can generate a sequence. Start the seed. The seed could be K multiplied, so add K to it becomes 2K. Add another K to it becomes 3K, so on and so forth and take the prime number. And model. In fact another way is that the C code. You start with some weird odd number and odd number is always relatively primitive or any power. So you just keep adding the articles to the itself. And see everything is more total because of integer. Right. So basically, so these are really faster engineering? Oh, and I don't want you to go on in depth of why this method works. Whatever. Honestly, if you're interested about it, go read about it. Want you to first get two things very clear number one. No perfect randomness. It's also the randomness. There are some of these ideas that gets from number K generally where they are coming from if you are previous it comes from like number theoretic results. And you can use those ideas to generate. A random number of generators. So if somebody ask you to write a code for a random number generator. Questions. If you are just going out and somebody wants to test your experience about, do you even know about SO? Good thing to know. But then you're going to use this. So from now on we'll assume we have access to a random number. Right. And if you have silver, where do they come from right. I mean you can read more or ask question now, but for now we are going to move into what is hashing and what are hash functions and we are going to look into analyze has functions and for from here on we will always assume that you have a random number like rank function and Python or Java or whatever you use is available to you. We know where it comes from. OK any questions so. OK. How many days we know about? OK we are going to be. OK. So. So you give it anTypical. You're probably around one question. When you google meta, wherever you're going in places, is given an arrow of integers, and this array makes a lot of duplicates. I want you to output an array that does not contain. How will you solve it? So the most naive idea is N square well. I look at an eye. I will insert the first number. Let's see if the number is repeated in the whole array. If it's not, then do nothing. If it's repeated, delete those are, mark for, mark them with something minus 1 or something. It's a comparison. They go and start. Now at this point of time I want to take a pause and make sure that everybody knows what is a big goal rotation. Anybody has problem with big bowl rotation? OK. Great. That's basic. So this is. OK can you do better than Order Square? Any thoughts anyone? Yes. I mean you could have a set and for every number you haven't seen it before and for the set and if you have seen the current number in the set policy. But then if you have seen in the set, that's still order of K, that K is the size of the set. Sorry, so the operation of whether I am assuming you are looking at a number you are adding in a side if you are not seeing it before. Now adding to the set. Or seen it before means you have to go back and see what all those people so imagine you are in the middle of having. And you got a number, you will still need almost order and to know whether you have seen it before or not. Starting. If you added everything. To where it's not added, on what the number is based on where it got added and what that requires. So like each number is associated with a spot in an array OK, so you've already got back to that in a second. There is a clean solution, which is environment. When you just make one pass. And you see replication close by. So you will see a number and if the next number is not that number you can the next number is not. If the next number is the same number, delete the next number is the same number. So you can do nlogn sorting OK. Are you guys with me here? N log N for sorting? Everybody gets that part and then one more pass to figure out. So N log N was ordered. What if you have? Such that. You can map any teachers you need to be into zero to M - 1. So let's say I'm a just looking at numbers in the array of energy that should even be strings. But if I have H of X uniquely mapped to something to be 0 -, 1, I can do it in order N. Is everybody with me here or? Do a quick explanation of what's happening here. So let's say I have an. There are a lot of information there. What I will do is I have a hash function such that H of X uniquely match between 0 to N 1. A somewhere is also a two and three game because I'm just in order big one OK. What I will do is I will hash 5. And create a big adding. So this is a big adding. So let's say the range is three times. In case like 2345 seconds. So I have this adding of size CN minus one. I will hash 5 wherever it goes, I'll mark it one with all starts with you so it's a bit this is a great idea. Hydrophilic market HF7 market hmm 5 again, market doesn't matter. It's already marked and in the end, just walk over this area wherever there is one. They do it in this one class and whatever the size of this is. Me. And I mean, by the way, this is not mathematics, this is computer science, right? So the difference between math and computer science? Here somehow accessing a memory location is a constant time operation. But I am hashing file to be. 225. I'm going to the location 225 and Market Spot Mall and to go to location 225 I don't have to travel. Right, so somehow accessing a memory location is a constant time and that allows me. To go beyond analog. There's no map here. If you want any comparison based on sorting this and log N is a limit. For the fact I can go from memory location in a constant time allows me. Get your nail allowance. I remember this fact is going to be the crux of 50% of the thing that we're doing this. The cross says somehow if I can map everything to a memory location, right? Somebody just mentioned that if I have map everything to a memory location, the memory locations are manageable. Then that creates a magical ability. To solve that. OK so this this stuff is very important if we can map M uniquely. Remember this will not work. If I have X of 5 and X of 29 it will collide. This will not work. I cannot. I cannot do this cricket. So there is that condition is very important. The mapping has to be unique. And if I can do that, that allows me to. Very efficient. I'm just summarizing what I said in this slide. So first of all, for people who are looking for a definition of a hash function. A hash function is simply a mapping, a function a mapping. That takes an object of interest. And massive push on discrete range. Two things are important. It has to be a discrete range. If it's continuous, that's not hashing. Why? It should be allocated. See, you are allocating a memory location to that, so even if it's floating point number it's fine, but it has to be discrete. So do is fine. Except 2.2 needs to be allocated to a conversation. If it's continuum, I cannot do that. 2.2 is a hysteresis version of maybe a number line you're discretizing at a different level. That's fine. But the outcome has to be discrete because I am allocating a memory location for the output. I am mapping the output into a memory location. So the output has to be discrete. And if something is discrete, you should be able to map it to zero to. And the sub counting works. And it takes an object of it. Now we'll call a hash function perfect if we have these two properties. What is the property? Sorry, just one property. That if there are two objects. They are not equal, but their hash value should not be. Also call. It's a function. So if I give it an O-1 and I give it O-1 again by definition of function it should back to the same value OK. I am just refreshing in your mind some very basic math which is what is the definition of information right? So I mean, again, like some people don't have access and all that's easy for others, you know, just, you know, some, some bear. Basics. And one important property which is not really here is if two objects are not equal, I don't want their hash value to be equal. And if I have these two property. Then I would say that this hash function allows me to search the space of object verification. The souls duplicate detection, everything becomes easy. If I cannot have this function. Then either I can sort it or excess. For example strings. I don't know how to sort strings, so there will be no problem. But if I get hash strings. So given a dynamic connection of an object, efficient searching and addition is possible if you have a. Any questions? How many of you have worked with certain hash function like hash maps? Have you used these data structures like hash threads? Hash maps your text when you're adding things to addiction, it uses internally. Now, one of the biggest problems in action is why this definition is great. It's almost. So perfect hash functions are hard. It's only it's good for. Numbers. There are certain cases where you can find perfect hash functions. Right. Those are very trivial cases or very specialized cases, but you will not have contact. So this property is too much lost. And all your albums look right, which talks about order, M, searching. So you must have order searching, searching the hash tag is, it's not model one because there is no. Questions. Comments. On SO perfect has functions are hard. We'll come back to this again and again. We realize that OK this is hard. If all are not equal to O2 then I want this to be guaranteed that I chop over is not equal to H of O2O2. What do you can get and what is reasonable? Is if O-1 not equal to O group H1O? One is not equal to HO 2 most of them. And we're trying to formalize when I order means but. This is something that is easy to get if most of the time is but. By the way, anybody has an idea of how to build perfect hash functions? So let's say I give you a dictionary of a millions OK. And I ask you generate a hash function such that every string is mapped. So so just just to zoom down this a bit, I want you to understand the complexity of this. So you're saying OK, you're giving me millions times. And let's say I want to be able to search this collection. So let's say somebody gave me a string. Remember the browser cache problem and you're like. Does this ring appears in this set? Well, searching is order one if I have a perfect hash function OK. So imagine I have this magical hash function that maps every string to a unique value. Then I create a bit map. Add all the strings in those bitmap and if I get a new string I just see the bitmap is zero1 right? I solved that problem in almost without even remembering any of the stuff you see. I don't know how to remember the strings, I just need the bitmap and I just need the attachment. Unfortunately, we generate that hash function assign every string a unique value. You need to have a dictionary. We basically add every string for dictionary and add a value 1, then another string add a value two, another string, add a value 3. How do you search the station? Searching is order N in this dictionary. Computing the hash function is order N. So yes, if you have a hash function, you solve the problem where it's like, you know, chicken and the egg problem to solve that original problem computing the hash surface. So computing the hash function itself is as hard as solving the searching problem. So having a perfect hash function. Even to compute that hash requires order N. So that tells the whole part of this. Nobody was asking me how much time it takes to calculate this. If it takes order N to calculate this, then it's over X square. And having a perfect hash function means. You're traversing a dictionary to know what. OK. So let's state a step back and summarize, because things are moving a little bit faster at. You know, you guys are not prepared for. We are talking about typical hash functions that you see in your Java hash Max hash. Generally, those doesn't seem so. They are actually very fast because they don't. Now we are trying to argue that hashing has magical infinities. For example, this problem if. I have a hash function. And if I can calculate the hash in constant time? Then I can solve this problem order N time. So having a perfect pass and being able to calculate that efficiently both of them seen. Right. Having a hash means uniquely mapping objects to a distinct value and being able to calculate that order one time. Very efficient, otherwise it doesn't work. Unfortunately, having a perfect hash is possible, but the computation times of that is going to be on. And this is the tradeoff that we are going to play. So what we are going to do is we are going to relax the perfectness of the hash function. And we'll get something. That allows us to calculate the hash value. Efficient, but. If we relax the perfect nature of the hash function, then what happens to the algorithms? That is what we use OK. So again what we are going to expect is OK. I am relaxing and why am I relaxing? Because it is mathematically hard. Again, it is not coming to be hard. Just like a certain difference, it is fundamental. There are a lot of connections for which you cannot have a perfect hash function without spending order. So what we are going to do is we are going to go OK. We give up on having a perfect passion itself. Personally, approximately. But. And what was the reason for perfect hash function OK if I give you two objects that will have different keys? Here we'll say if I give you two different object, it is very likely with very hand property that they will have different things. So obviously if I use that I duplicate detection rates. Right, because now I cannot guarantee the things you're So this.SSo this you see what where we are going from the first lecture, we are going to have to. We gain a lot of patience. efficiencyOK.  Let's do a little bit of formal exercise. What is the universal? Well, a universal hashing says that OK I will have a range, a range from zero to some capital M, some M. So you give me an object and how do you do the sun? That's an E. Of the heart. Now, if you get to two different objects, they will very likely have to, in fact. I will give you the quantification of that more likely that. Assume you're throwing objects randomly into zero to. You give me an object and I end buckets and I'm just going this ball and uniform. And if I do that then two different objects will provide probability 1 / N. OK. So I will say that if two objects the probability of collision is at least sorry, at most 1 / M. Then I will call this a good habit. So given two objects again I can remember the definition is also like important for probabilistic perspective. And I promise this is only going to be there for few lectures because then just like we got. Available to us and we'll start OK and then we'll go to the implementation. But I want a liberty to really understand some separate piece that is going on. What we are doing is we are taking an object. And we are going to define a very cheap functions that is going to map these object into some range 0 to it. The properties that both of them will have the same hash function will be at most 1 / N. I will rewrite everything like duplicate, detention, searching, sorting with these kind of imperfections. And then we'll show that the desert actually almost as well as the best case that we have perfect. With some exceptions, because we have to play something, we create some certainty and we'll talk about that. Next. Just bear with me for some time because we're just working something. OK so. Call a family universal. If the probability of collision is at most one over. One definition. So we saw a universal atomic family or universal hashing family. You know edge is more or less random. It's like edge acts randomly given any object has no memory control, like throwing it randomly perfectly randomly into zero. There is a particular family which is interesting because it's very easy to create those is called too universal. And why it is called too universal? Because it says well, I cannot guarantee perfect randomness. We will see in later that it was perfect randomness. What I am going to is you give me two objects, so give her two objects. Previous one, the universal family was. Anything you give me the probability of collision will be here. It's a very specific attention given two options if they are not equal. And for these two any two given object. Yeah. So it's random with respect to a given form. And why am I studying this? Because there is a very easy way to. Hey, Cortana. Again, I'm not going to hold the. Definition here. There's a lot of here. You're going something uniformly from a family and all that. We'll talk about that in a second. But you, let me show you. Basically what you're hash from somebody going to look like is. We don't deal with ourselves because then. That means that. AX plus, B, Mod, B, and A and B will be random, but then A has a range. A will be between 1 to B -, 1 and G will be between 0 to T, -, 1. Now before we go there, we want to show that this is AA family that follows that OK. So why are we studying two universal family? Let me just remind everybody we are looking for hash functions that are almost very cheap to compute. So remember, what is the problem in having a perfect hash function? It's not cheap to complete. So we need to realize the definition of perfect noise in a certain way. But one of the important consideration is the hash function has to be cheap, otherwise the algorithm should be faster. So there is a parameter of hash options that we'll work with that are very cheap to compute, and they are two universal time. But what we are doing is we are showcasing a very cheap to compute hash function. We will study properties and then we can argue that instead of using a perfect hash function, use these hash functions and you will still get very efficient algorithms. OK. So this is an interesting parallel called two universal hashing function. And two universal action says that if you give me two website give an XML, I can very easily give you a hash function. Such that the collision. Opportunity if object one or X and Y are not equal is at most 1 over. Now why we call it a hash family and all? So first of all. Now the interesting part here is this is a notion of probability. So where is the pseudorandom? Where is the random number? Where is the probability? And how does this all work? Those are the three things that we have to clarify. And once that's clear, it's it just becomes an implementation. So what we are arguing is that imagine. That I have me. What is P into P -, 1 functions. So I have a family of five functions. For the family is X1, X2. OK. So let's say H1 is you pick a equal to one and B equal to zero. H2 is you pick a equal to 1B equal to one. OK HP into P -, 1 as you put a equal to P -, 1 and B equal to. You see what I'm saying? So this is a family. The hash function is the form AX B mod. OK and these are all functions. All the possible functions. So this is my family. And let's say I uniformly pick a function from here. So two things to clarify. There is a function space of function and. I am picking a function uniform. OK but I only pick one function on this. And the argument is under this probability of pitting. The collision between X and Y if X and Y are not equal, will have this property. You can actually do this. It's not difficult. Using simple number theoretic argument, when can 2X and Y have the same mod P and you will see that there are only 1 / P -, 1 choices. So, and this is more than anything, you can loan that for the 90. Imagine N and B are the same possibly and you can move this again, our goal is not to prove it. The goal is. Want to understand what this function is so that we can implement. OK proof part is also like depend on how much modular arithmetic you want. Again people who are taking this drives you can go online and get simple proof on wikipedia. So very simple argument. Let's just go and like write down the proof of file. So forget about what is written in the last slide. How about the 3 1/2? So what I'm trying to show you is a mathematical result that will. Give your construction of that. What do we want? We want that OK give me a hash function. Such that if I give you X and Y then they collide with X at most 1 / N probability where N is an image. Now I'm giving you a hash function whose range is. For the time being P there has speed range and for the time being for sake of simplicity we are not asking OK. So I have arranged will be fine. Hey, Cortana, there's a family. And if I uniformly draw because we are arguing what probably there is probably coming in picture, as I said everything is. But what am I doing is if you stand but a uniformly from this family, but there is some amount of standing now the randomness. There is a probability of one / 2 D - 1 at this suicide. There's a probability as now under that information solution. You can actually show this as a. OK So what you are saying is my ask function is a uniform sample. From this how do I uniform sample? Anybody knows how to operate a uniform sampling on this? Assume you have random number. So we have taken care of random number generation. And you can generate random number between any two range. Of numbers. Yeah, so one way is OK I inherit 012B minus one, take a random number between 0 to P and P -, 1, whatever that random number is associated with the. You know what is an easier way? That I know the form of the function. Pick a randomly a from zero to T minus 1, from one to T - 1, pick B randomly from 0 to P -, 1 and that ax B mod P is a random sample from this. OK so our hash function will be. OK randomly generate a from zero to B -, 1 randomly generate B from one to P 1 randomly generate P from zero to P1 and I have a number. Say here this is only, this is P -, 1 and this is. So that is how I. So sampling an edge uniformly from here, remember that's where the probability is coming. There's a probability of collision. What do you mean by probability of collision? Where is the problem? Well, the probability is under A sampling. On this family and the way I'm sampling is. Being a random A and a random B and that is a uniform sample from this and under that uniform sample, the probability that 2X and Y will have the same hash value will be at most 1 / P - 1 / P. So that is. That is the notion of property that we are going to extract it out. So generally are the hash functions will be will generate A and B independently and uniformly. So that will be our. Hashem. So our hash function just require two numbers. And computation is faster. Time is AX plus, B, mod, B, sub mod, N. Again, why do you need two mods? Because P is a prime and N is a range and the range may or may not be prime. If the range is prime, key works. The range is not going to do some additional edge cases. But it's going to be as simple as this. And all I need is three numbers AB and T that will be. OK. Now whenever we use probability. But the use of probability and other sound. So when we are doing the analysis. We'll assume the. But when we are doing the implementation. It's very easy. Save AB randomly and save it. Now you will ask a question. Wait a second. Once I save A and B my hash insurance deterministic. OK the moment, I say, A and B. There's no randomness. So how are you calling the probability of collision? Well, the probability is over the randomness of sampling. And why it works? Yeah, this is a. Very fundamental results which a lot of these it is a part of principle of different decision problem. So what is principle or different decision? It says let us say I am trying to create a experiment. Let us say I go walk this way. Then I flip a coin and if the point is head I make the left. If the point is states I make a run OK and then I do this at every stop. So let us say I start here and every time there is an intersection I either take left or right using a form. Obviously this is. Now what principle of referred decision says is, well you can either prefilter. So let us say I require 20 point flips to reach at a place. Now either you can do the point flip while you're experimenting, so every time you reach an intersection, you flip a on or. You can pre flip 20 points either. Don't show it to me, it's already flipped. OK don't show me whether the heads or tails when I reach at thaSimply argue that 0 you give me X and YI can assume that the probability of collision between X and Y is not going to be more than 1 over N. OK. So if you have understood this part. Then from here onwards. Whenever we are trying to analyze the collision event or something, we have the capability to quantify the probability of. And once we can quantify, a lot of adistic things will happen. Like we'll be able to argue how efficient this will be, how much work needs to be done. Two things to note here is. It's very efficient to calculate this. The reason why we could use a probability argument even though the functions. So remember whenever you are going to do blue filters, any experiment you will sample A and B. Storage. That is your hash. You want another hash function. You will resample AMD store it. That is your number. And that is how you will generate universal atoms. And once you generate universal hash functions you can do min hash. And when we are going to do the analysis, the reason we will be able to do the analysis. Because of the principle of effort this is. All we have done is flip the points which are. Since. We were independently sampled. I can make this up. And it will be two by which you can actually even verify. It's one of the very powerful principles and probability, which is kind of obvious. Right. It doesn't need to be taught and so on either point right now or somebody flipped it for me and stored it. It's the same thing right? Property wise it doesn't change any, but because somebody flipped it and stored it, allow me to algorithmically use it. Because if I am first of all flipping the coin, flipping the point during experiments is 2 problems. One is obviously it's inefficient. Two because of inconsistent. By the absolute meaning, OK anyway. Forget about that. Let's let's a little talk about. Searching using the So what we're going to do is. We are going. We are going to use. These family of hash functions universal hash functions. I showed you an example of a two universal hash function. Will go into three, 4 and 5 again as well. It will basically will will come back to that later, but universal hash functions will be our resources. But remember we compute the hash and faster high. We are going to resolve most of the problem with this hash function. So let's start with a simple problem of. Insertion and search. For example, I have a bunch of integers, you have to insert it and you have to search. So let us say you have a table of size 10. Let us say you do some sampling and you get HK is a mod 10 so a turn out to be one and B turned out to be zero. So let us say this is your hash function, obviously a we are stored so this becomes your hash. And again like you have to insert 718, 41 and 94 what you will do is I will take seven what is 7 mod 10? 7 is 7 mod 10 so I will insert 7X. If I get 1818 is 8.10 so the hash value is eight so I will insert 80, similarly 94 and 40. Ben. So this is the right? OK so this is how insert channel. OK. Now obviously in this case there was operation. So the hash functions are perfect, even though they were not designed to be perfect. What happens when there is a code OK? And why are we doing this? Because remember, we are trying to mimic a world where we have a perfect action. So in the world when there is a perfect hash function, you just hash an element, insert. You have to search for it. You just hash it. Search now that. We know that hash function hash computation itself is R. So what we are going to do is we are going to use these universal hash methods. Now obviously universal hash functions are passed because I can calculate the hashing node now. But then I had to deal with something called collisions, because I know that even though it's not, it's not frequent. It's still possible to have two elements at the same action. So now I have to modify my insertion. So what we have to do is we have to do what we do, collision resolution. But then what we are studying is how your hash sets are. If you have ever used hashtags in Javascript or hash sets in your pipe, right? You say just a set. Most of the set is implemented as a hash. So when you do a set implementation in Python. It is essentially doing something like this. There is a simple universal of some action. But we'll see one of that generation when we go to the 1st exercise. Something like double hash or something. When you hash the elements and because there are collision, you follow some collision resolution. Now there are two ways to solve collision, once for separate chaining and the 2nd is for linear programming or whatever you have about a probing the word probing. So we'll look into what is those. So one idea to resolve collision is. Obviously now I cannot have a texture like this, so I have to keep something for collision. For example if I get 2424 will collide to 24. Again, I'll use anatomy. Or maybe I can, but let's see. So one of the earliest idea was OK. Don't use an ad. The array is basically just a pointer. So now in our previous case, let's say I'm not 3740, 1, 18 and instead of 24 and ninety four seven. So when we are having sur 7 at 7, I have to insert in bucket 7 and bucket 7 is actually a linked list so first seven goes away. Then 41 goes to one. Heating was too big and I was 70. Wait a second. Is providing itself, but that's OK because I will emphasize. That's changing. This idea is one separate chain, 2 OK. Now obviously what is my insertion time? My insertion time is whatever is the length of the nickel is at that position. And same as my search time is whatever is, so I go to a bucket and whatever is the length of the chain at that bucket is my search. OK is that OK if I am changing and I am using two universal. So my actual today is more or less work we showed you at Kmart and something like that. Obviously we don't know what exactly it is because we don't know the sample. But once we sat perfectly, so I have a high. And if I use the studio it was a function. And let us say I am inserting MMM objects into M at size N. So my hash function range is M. And I'm inserting M objects. So what is the worst case searching time for now? Why inserted M objects into that and now searching and all? What are the worst case searching now? Off and small and because what would happen is all the M objects collided in one place so my length of the chain is M. So if I have to search I would travel. So worst case is as far as not doing any hashing. What is it? A speculative value of searching time with M, adding and M objects and serving. And the argument is that it's less than 1 + M - 1 only typically true, but it will argue that this is it's less than that. Which is a very interesting quantity because if N is more than M then this is a constant time search expectation. So I have a. OK. I'm trying to search an object. Let's say I have a search. So let's say hash of your lead goes to somebody. OK and then. Now what is? What is the name of this game? Remember I already inserted M objects. The M objects went into the set. OK all the objects are connected. So what is the expected number of objects that came? That's the only thing I have. OK. So there are two cases you will say why there is one + M - 1 over. There are two cases. OK and so. Yes. So this is the bucket of address. Where my parents wedding is going I'm not interested in her because I by the way is this any particular puppet? But cube goes uniformly so I don't care which one. This is a bucket that Q goes to and that is what happens. Now I have objects called O-1 O2O that is already inserted. OK So what is the length of the chain here? Now one interesting case would be that Q is part of O-1, so there is a special case where there is Q. Yes or no? The argument is that Q is there. Because I know Q goes here, this must go. Probably about going there is one if Q exists. But if Q does not exist, and irrespective of whether it exists or not, let us ignore the cycle. Listen, there is always an object, one here or one to us. OK and I still have my office. Why is it a minus 7, 1 and four weeks? Yeah, because of probability of what is the probability of O-1 coming here? Why is it going by hand? Because the property of collision with you. Basically propagating of a collision. With any objects I. I know that many objects hash value in query. Right this. Property which is less than. The property that this guy come here is. Probability that this guy come here is less than one over N the probability that this guy come here is less than one and then simply by linearity of expectation. The length of the chain. Is going to be M - 1 / N One Plus M - 1 /. OK, that's that's up, right? OK so we have almost 30 out of 5 minutes. Producers. We relax the motion of having a perfect action. We figure out a way to avoid collisions. That if I have compromise function I don't need to, but I don't have perfect iPhone that's why I need change the worst case is bad. But that is is the best case? Is order one more or less? But expectation is not. So before the trailer of mods coming in the next class by the next class, we'll do a little bit more of a math tool into some inequalities that will be there. And why we need that, remember? Expectation is where you take but. It requires also. For example if I have a number, let us say I have a number in my bag is now it should be minus Infinity or plus Infinity. With equal property but the expectation is 0. The expected I will give you some picture but it doesn't give you all. We will need certain set of tools. To be able to argue more about why this is a good example OK and for that. We need inequality and that is what we will see in the next class. And then we will come back to this again and talk about chaining and probing and see what what. Is great. At least we have one week to submit. Week may submit. 