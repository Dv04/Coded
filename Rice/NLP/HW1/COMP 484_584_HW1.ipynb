{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81437c5",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 1 — Coding\n",
    "\n",
    "**Dataset:** AG News (4 classes)\n",
    "\n",
    "**Undergrad Required:**\n",
    "- Part 1: Binary BoW\n",
    "- Part 2: Count BoW\n",
    "- Part 3: 2-layer neural classifier\n",
    "- Part 4: Train/evaluate and compare Binary vs Count\n",
    "\n",
    "**Graduate Required / Undergrad Bonus:**\n",
    "- Part 5: TF-IDF BoW + same classifier + short analysis\n",
    "\n",
    "---\n",
    "**Hints**\n",
    "- Tokenizer, vocabulary, and dataset split are provided.\n",
    "- Use PyTorch autograd for backpropagation.\n",
    "- Do **not** use transformers or LLM embeddings/models.\n",
    "\n",
    "Complete the `# TODO` sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc133f3e",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a55ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/homebrew/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07924098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Local install (inside your conda env):\n",
    "#   pip install datasets torch scikit-learn numpy\n",
    "\n",
    "import math, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4146945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 120\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b5792",
   "metadata": {},
   "source": [
    "## 1. Load AG News + create train/dev split (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5b2345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108000, 12000, 7600)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"ag_news\")\n",
    "train_ds = ds[\"train\"]; test_ds = ds[\"test\"]\n",
    "\n",
    "dev_ratio = 0.1\n",
    "n = len(train_ds)\n",
    "idx = np.arange(n)\n",
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(idx)\n",
    "\n",
    "n_dev = int(n * dev_ratio)\n",
    "dev_idx = idx[:n_dev]; tr_idx = idx[n_dev:]\n",
    "\n",
    "train_texts = [train_ds[int(i)][\"text\"] for i in tr_idx]\n",
    "train_y     = np.array([train_ds[int(i)][\"label\"] for i in tr_idx], dtype=np.int64)\n",
    "\n",
    "dev_texts = [train_ds[int(i)][\"text\"] for i in dev_idx]\n",
    "dev_y     = np.array([train_ds[int(i)][\"label\"] for i in dev_idx], dtype=np.int64)\n",
    "\n",
    "test_texts = list(test_ds[\"text\"])\n",
    "test_y     = np.array(test_ds[\"label\"], dtype=np.int64)\n",
    "\n",
    "len(train_texts), len(dev_texts), len(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2699d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5000, 5000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell is used to speed up debugging of your training code by using only a subset of the training, \n",
    "development, and test data. Remember to set it to None for the final run before submitting your homework.\n",
    "'''\n",
    "\n",
    "LIMIT_TRAIN = 30000\n",
    "LIMIT_DEV   = 5000\n",
    "LIMIT_TEST  = 5000\n",
    "\n",
    "if LIMIT_TRAIN is not None:\n",
    "    train_texts = train_texts[:LIMIT_TRAIN]\n",
    "    train_y = train_y[:LIMIT_TRAIN]\n",
    "if LIMIT_DEV is not None:\n",
    "    dev_texts = dev_texts[:LIMIT_DEV]\n",
    "    dev_y = dev_y[:LIMIT_DEV]\n",
    "if LIMIT_TEST is not None:\n",
    "    test_texts = test_texts[:LIMIT_TEST]\n",
    "    test_y = test_y[:LIMIT_TEST]\n",
    "\n",
    "len(train_texts), len(dev_texts), len(test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413d9c2",
   "metadata": {},
   "source": [
    "## 2. Tokenizer (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0ef9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def tokenize(text: str):\n",
    "    \"\"\"Word-level tokenizer: lowercase + alphanumeric tokens.\"\"\"\n",
    "    return re.findall(r\"[a-z0-9]+\", text.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe3fc2",
   "metadata": {},
   "source": [
    "## 3. Vocabulary (provided; built from TRAIN ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b30a9f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def build_vocab(texts, vocab_size=20000, min_df=2):\n",
    "    df = Counter(); tf = Counter()\n",
    "    for txt in texts:\n",
    "        toks = tokenize(txt)\n",
    "        tf.update(toks); df.update(set(toks))\n",
    "    candidates = [(tf[t], t) for t in tf if df[t] >= min_df]\n",
    "    candidates.sort(key=lambda x: (-x[0], x[1]))\n",
    "    kept = [t for _, t in candidates[: max(0, vocab_size-2)]]\n",
    "    vocab = {PAD_TOKEN:0, UNK_TOKEN:1}\n",
    "    for t in kept:\n",
    "        if t not in vocab: vocab[t] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(train_texts)\n",
    "V = len(vocab)\n",
    "print(\"Vocab size:\", V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f1a0b",
   "metadata": {},
   "source": [
    "## Part 1 — Binary Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55764c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 20000), (5000, 20000), (5000, 20000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def vectorize_bow_binary(texts, vocab, max_len=200):\n",
    "    \"\"\"Binary BoW: X[i,j]=1 if token j appears in doc i.\"\"\"\n",
    "    V = len(vocab)\n",
    "    X = np.zeros((len(texts), V), dtype=np.float32)\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = tokenize(text)[:max_len]  # Truncate to max_len\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                X[i, vocab[token]] = 1.0\n",
    "            else:\n",
    "                X[i, vocab[UNK_TOKEN]] = 1.0  # Map OOV to <unk>\n",
    "    \n",
    "    return X\n",
    "\n",
    "Xtr_bin = vectorize_bow_binary(train_texts, vocab)\n",
    "Xdv_bin = vectorize_bow_binary(dev_texts, vocab)\n",
    "Xte_bin = vectorize_bow_binary(test_texts, vocab)\n",
    "Xtr_bin.shape, Xdv_bin.shape, Xte_bin.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a58136",
   "metadata": {},
   "source": [
    "## Part 2 — Count Bag-of-Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e937d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 20000), (5000, 20000), (5000, 20000))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def vectorize_bow_count(texts, vocab, max_len=200):\n",
    "    \"\"\"Count BoW: X[i,j]=number of occurrences of token j in doc i.\"\"\"\n",
    "    V = len(vocab)\n",
    "    X = np.zeros((len(texts), V), dtype=np.float32)\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = tokenize(text)[:max_len]\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                X[i, vocab[token]] += 1.0\n",
    "            else:\n",
    "                X[i, vocab[UNK_TOKEN]] += 1.0\n",
    "                \n",
    "    return X\n",
    "\n",
    "Xtr_cnt = vectorize_bow_count(train_texts, vocab)\n",
    "Xdv_cnt = vectorize_bow_count(dev_texts, vocab)\n",
    "Xte_cnt = vectorize_bow_count(test_texts, vocab)\n",
    "Xtr_cnt.shape, Xdv_cnt.shape, Xte_cnt.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5da05f",
   "metadata": {},
   "source": [
    "## Part 3 — 2-layer Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d62f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TwoLayerNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement a 2-layer neural network classifier:\n",
    "      Linear(input_dim -> hidden_dim) -> ReLU -> Linear(hidden_dim -> num_classes)\n",
    "    The output should be logits of shape (B, 4).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=256, num_classes=4):\n",
    "        super().__init__()\n",
    "        # Define the two linear layers and activation\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass: x -> Linear -> ReLU -> Linear -> logits\n",
    "        h = self.fc1(x)\n",
    "        h = self.relu(h)\n",
    "        logits = self.fc2(h)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513bcdd",
   "metadata": {},
   "source": [
    "## Part 4 — Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(Xtr, ytr, Xdv, ydv, epochs=5, lr=1e-3):\n",
    "    \"\"\"Train on full batches (no mini-batching) for simplicity.\"\"\"\n",
    "    model = TwoLayerNN(input_dim=Xtr.shape[1]).to(device)\n",
    "\n",
    "    # Use Adam optimizer and CrossEntropy loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Convert datasets to torch tensors\n",
    "    Xtr_t = torch.tensor(Xtr, dtype=torch.float32).to(device)\n",
    "    ytr_t = torch.tensor(ytr, dtype=torch.long).to(device)\n",
    "    Xdv_t = torch.tensor(Xdv, dtype=torch.float32).to(device)\n",
    "    ydv_t = torch.tensor(ydv, dtype=torch.long).to(device)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        # 1. Clear old gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        logits = model(Xtr_t)\n",
    "        \n",
    "        # 3. Compute training loss\n",
    "        loss = criterion(logits, ytr_t)\n",
    "        \n",
    "        # 4. Backward pass (autograd)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation on dev set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(Xdv_t).argmax(dim=-1).cpu().numpy()\n",
    "        \n",
    "        acc = accuracy_score(ydv, pred)\n",
    "        mf1 = f1_score(ydv, pred, average=\"macro\")\n",
    "        print(f\"Epoch {ep} | training loss={loss.item():.4f} | dev acc={acc:.4f} | dev macro-f1={mf1:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebea2d",
   "metadata": {},
   "source": [
    "## Part 4 — Train on Binary vs Count BoW and compare metrics (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7860ed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on BINARY BoW...\n",
      "Epoch 1 | training loss=1.3869 | dev acc=0.5294 | dev macro-f1=0.4962\n",
      "Epoch 2 | training loss=1.3488 | dev acc=0.7882 | dev macro-f1=0.7833\n",
      "Epoch 3 | training loss=1.2968 | dev acc=0.8420 | dev macro-f1=0.8401\n",
      "Epoch 4 | training loss=1.2332 | dev acc=0.8566 | dev macro-f1=0.8553\n",
      "Epoch 5 | training loss=1.1669 | dev acc=0.8620 | dev macro-f1=0.8608\n",
      "Training on COUNT BoW...\n",
      "Epoch 1 | training loss=1.3872 | dev acc=0.6640 | dev macro-f1=0.6642\n",
      "Epoch 2 | training loss=1.3388 | dev acc=0.8430 | dev macro-f1=0.8420\n",
      "Epoch 3 | training loss=1.2747 | dev acc=0.8698 | dev macro-f1=0.8700\n",
      "Epoch 4 | training loss=1.1970 | dev acc=0.8740 | dev macro-f1=0.8746\n",
      "Epoch 5 | training loss=1.1168 | dev acc=0.8780 | dev macro-f1=0.8789\n",
      "Binary dev/test: {'accuracy': 0.862, 'macro_f1': 0.8608441357810598} {'accuracy': 0.8622, 'macro_f1': 0.8596461114353106}\n",
      "Count  dev/test: {'accuracy': 0.878, 'macro_f1': 0.8788595951231623} {'accuracy': 0.8748, 'macro_f1': 0.8730707770464805}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def eval_model(model, X, y):\n",
    "    model.eval()\n",
    "    X_t = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_t).argmax(dim=-1).cpu().numpy()\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y, pred)),\n",
    "        \"macro_f1\": float(f1_score(y, pred, average=\"macro\")),\n",
    "    }\n",
    "\n",
    "print(\"Training on BINARY BoW...\")\n",
    "model_bin = train_model(Xtr_bin, train_y, Xdv_bin, dev_y, epochs=5, lr=1e-3)\n",
    "dev_bin = eval_model(model_bin, Xdv_bin, dev_y)\n",
    "test_bin = eval_model(model_bin, Xte_bin, test_y)\n",
    "\n",
    "print(\"Training on COUNT BoW...\")\n",
    "model_cnt = train_model(Xtr_cnt, train_y, Xdv_cnt, dev_y, epochs=5, lr=1e-3)\n",
    "dev_cnt = eval_model(model_cnt, Xdv_cnt, dev_y)\n",
    "test_cnt = eval_model(model_cnt, Xte_cnt, test_y)\n",
    "\n",
    "print(\"Binary dev/test:\", dev_bin, test_bin)\n",
    "print(\"Count  dev/test:\", dev_cnt, test_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c767e",
   "metadata": {},
   "source": [
    "\n",
    "## Required comparison (write your answer here)\n",
    "\n",
    "1. Which is better on dev/test: **Binary BoW** or **Count BoW**?\n",
    "2. Give 1--2 reasons (e.g., repeated topical words, length effects, noise).\n",
    "3. If the difference is small, why might both be strong on AG News?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d5158",
   "metadata": {},
   "source": [
    "1. Which is better on dev/test: **Count BoW** is better, outperforming Binary BoW by ~1.6% on the development set and ~1.26% on the test set.\n",
    "2. Give 1--2 reasons: \n",
    "   - **Signal Intensity:** Count BoW captures the frequency of topical keywords. In news snippets, a word like \"market\" or \"win\" appearing multiple times provides a stronger, more confident signal to the classifier than a single mention.\n",
    "   - **Feature Richness:** Binary BoW discards magnitude information, treating all word occurrences as equal, whereas Count BoW allows the model to learn that higher word density correlates more strongly with specific categories.\n",
    "3. If the difference is small, why might both be strong on AG News?\n",
    "   - **Short Document Length:** Since AG News contains short headlines and snippets, most informative words naturally only appear once or twice. In these cases, the sparse vectors for Binary and Count representations are nearly identical, leading to similar performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3e0da",
   "metadata": {},
   "source": [
    "## Part 5 (Graduate Required / Undergrad Bonus) — TF-IDF BoW (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a40b157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on TF-IDF BoW...\n",
      "Epoch 1 | training loss=1.3886 | dev acc=0.8656 | dev macro-f1=0.8664\n",
      "Epoch 2 | training loss=1.1463 | dev acc=0.8874 | dev macro-f1=0.8880\n",
      "Epoch 3 | training loss=0.9012 | dev acc=0.8938 | dev macro-f1=0.8945\n",
      "Epoch 4 | training loss=0.6703 | dev acc=0.8972 | dev macro-f1=0.8980\n",
      "Epoch 5 | training loss=0.4931 | dev acc=0.8992 | dev macro-f1=0.9000\n",
      "TF-IDF dev/test: {'accuracy': 0.8992, 'macro_f1': 0.9000032485095907} {'accuracy': 0.8896, 'macro_f1': 0.8884607478816314}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_idf(train_texts, vocab, max_len=200):\n",
    "    \"\"\"\n",
    "    Compute IDF over TRAIN ONLY.\n",
    "    df(token) = number of training docs containing token at least once\n",
    "    idf(token) = log(N / df(token))\n",
    "    \"\"\"\n",
    "    N = len(train_texts)\n",
    "    V = len(vocab)\n",
    "    df = np.zeros(V, dtype=np.float32)\n",
    "    \n",
    "    for text in train_texts:\n",
    "        tokens = set(tokenize(text)[:max_len])\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                df[vocab[token]] += 1\n",
    "            else:\n",
    "                # We can track df for <unk> too\n",
    "                df[vocab[UNK_TOKEN]] += 1\n",
    "                \n",
    "    # Use max(1, df) to avoid division by zero, though min_df=2 in build_vocab handles this\n",
    "    idf = np.log(N / np.maximum(1, df))\n",
    "    return idf.astype(np.float32)\n",
    "\n",
    "def vectorize_tfidf(texts, vocab, idf, max_len=200):\n",
    "    \"\"\"TF-IDF with raw TF: X[i,j] = tf(i,j) * idf(j).\"\"\"\n",
    "    # First get the raw counts (TF)\n",
    "    X = vectorize_bow_count(texts, vocab, max_len)\n",
    "    \n",
    "    # Multiply each row by the IDF vector\n",
    "    # X is (N, V) and idf is (V,)\n",
    "    X_tfidf = X * idf\n",
    "    \n",
    "    return X_tfidf\n",
    "\n",
    "idf = compute_idf(train_texts, vocab)\n",
    "Xtr_tfidf = vectorize_tfidf(train_texts, vocab, idf)\n",
    "Xdv_tfidf = vectorize_tfidf(dev_texts, vocab, idf)\n",
    "Xte_tfidf = vectorize_tfidf(test_texts, vocab, idf)\n",
    "\n",
    "print(\"Training on TF-IDF BoW...\")\n",
    "model_tfidf = train_model(Xtr_tfidf, train_y, Xdv_tfidf, dev_y, epochs=5, lr=1e-3)\n",
    "dev_tfidf = eval_model(model_tfidf, Xdv_tfidf, dev_y)\n",
    "test_tfidf = eval_model(model_tfidf, Xte_tfidf, test_y)\n",
    "\n",
    "print(\"TF-IDF dev/test:\", dev_tfidf, test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e99609",
   "metadata": {},
   "source": [
    "\n",
    "## Graduate/Bonus analysis (write your answer here)\n",
    "\n",
    "Compare **TF-IDF** against Binary/Count BoW:\n",
    "- Is TF-IDF better or worse on AG News?\n",
    "- Why might TF-IDF help topic classification? When might it hurt?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55661191",
   "metadata": {},
   "source": [
    "- **Is TF-IDF better or worse on AG News?**\n",
    "  TF-IDF is significantly **better**. It reached 89.92% dev accuracy, which is 2.1% higher than Count BoW and 3.7% higher than Binary BoW. It also converges much faster, outperforming Binary's final results in its very first epoch.\n",
    "- **Why might TF-IDF help topic classification? When might it hurt?**\n",
    "  - **Help:** It effectively filters \"noise\" by penalizing high-frequency words (e.g., \"said\", \"from\") that appear across all categories, while amplifying rare, discriminative words (e.g., \"semiconductor\", \"league\") that are highly specific to a single topic.\n",
    "  - **Hurt:** It can hurt if there is a **domain shift**. Since it relies heavily on the specific rare words of the training set, it may be less robust than Binary BoW if the test set introduces new terminology or if the importance of rare words changes significantly between datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
