{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "Starting training...\n",
      "Episode 1/5\n",
      "Episode 2/5\n",
      "Episode 3/5\n",
      "Episode 4/5\n",
      "Episode 5/5\n",
      "Training completed.\n",
      "Starting testing...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Approved       0.61      0.52      0.56       536\n",
      "    Rejected       0.35      0.45      0.40       318\n",
      "\n",
      "    accuracy                           0.49       854\n",
      "   macro avg       0.48      0.48      0.48       854\n",
      "weighted avg       0.52      0.49      0.50       854\n",
      "\n",
      "\n",
      "\n",
      "Predicted loan amounts: \n",
      "[11672174.524459839, 6109957.480170436, 14786835.493971432, 6109957.480170436]\n",
      "\n",
      "Actual applied loan amounts: \n",
      "[12300000, 5000000, 1500000, 10000000]\n",
      "\n",
      "\n",
      "Predictions:\n",
      "\u001b[31mTest Case 1: Loan will not be approved\u001b[0m\n",
      "\u001b[32mTest Case 2: Loan will be approved\u001b[0m\n",
      "\u001b[32mTest Case 3: Loan will be approved\u001b[0m\n",
      "\u001b[31mTest Case 4: Loan will not be approved\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps (from your template)\n",
    "print(\"Reading dataset...\")\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status before dropping\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Scale the target variable as well\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Parameters for TD3\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = 1  # Continuous output (loan amount prediction)\n",
    "learning_rate_actor = 0.001\n",
    "learning_rate_critic = 0.001\n",
    "gamma = 0.99  # Discount factor\n",
    "tau = 0.005  # For soft target updates\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "policy_noise = 0.2\n",
    "noise_clip = 0.5\n",
    "policy_freq = 2\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Define Actor and Critic networks\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + action_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        a = (\n",
    "            a if a.dim() == 2 else a.unsqueeze(1)\n",
    "        )  # Ensure action tensor has correct dimensions\n",
    "        x = torch.cat([x, a], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Initialize Actor, Critic, and their target networks\n",
    "\n",
    "actor = ActorNetwork(input_size, output_size)\n",
    "target_actor = ActorNetwork(input_size, output_size)\n",
    "critic_1 = CriticNetwork(input_size, output_size)\n",
    "target_critic_1 = CriticNetwork(input_size, output_size)\n",
    "critic_2 = CriticNetwork(input_size, output_size)\n",
    "target_critic_2 = CriticNetwork(input_size, output_size)\n",
    "\n",
    "# Copy weights from the original networks to the target networks\n",
    "target_actor.load_state_dict(actor.state_dict())\n",
    "target_critic_1.load_state_dict(critic_1.state_dict())\n",
    "target_critic_2.load_state_dict(critic_2.state_dict())\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate_actor)\n",
    "critic_1_optimizer = optim.Adam(critic_1.parameters(), lr=learning_rate_critic)\n",
    "critic_2_optimizer = optim.Adam(critic_2.parameters(), lr=learning_rate_critic)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Soft update target networks\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, source_param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            tau * source_param.data + (1.0 - tau) * target_param.data\n",
    "        )\n",
    "\n",
    "\n",
    "# Train the TD3 model\n",
    "print(\"Starting training...\")\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    print(f\"Episode {episode + 1}/{n_episodes}\")\n",
    "    for i, state in enumerate(X_train):\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action = actor(state_tensor).detach().numpy().flatten()\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(y_train_scaled[i] - action[0])  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(np.array(states))\n",
    "            actions = (\n",
    "                torch.FloatTensor(np.array(actions)).unsqueeze(1)\n",
    "                if actions[0].ndim == 0\n",
    "                else torch.FloatTensor(np.array(actions))\n",
    "            )\n",
    "            rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "            next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "            # Add noise to target actions\n",
    "            noise = torch.clamp(\n",
    "                torch.normal(0, policy_noise, size=actions.shape),\n",
    "                -noise_clip,\n",
    "                noise_clip,\n",
    "            )\n",
    "            next_actions = target_actor(next_states) + noise\n",
    "            next_actions = torch.clamp(next_actions, -1, 1)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            target_q1_values = target_critic_1(next_states, next_actions).detach()\n",
    "            target_q2_values = target_critic_2(next_states, next_actions).detach()\n",
    "            q_targets = rewards + (\n",
    "                gamma * torch.min(target_q1_values, target_q2_values)\n",
    "            )\n",
    "\n",
    "            # Compute predicted Q-values and update Critic networks\n",
    "            q1_values = critic_1(states, actions)\n",
    "            critic_1_loss = loss_fn(q1_values, q_targets)\n",
    "            critic_1_optimizer.zero_grad()\n",
    "            critic_1_loss.backward()\n",
    "            critic_1_optimizer.step()\n",
    "\n",
    "            q2_values = critic_2(states, actions)\n",
    "            critic_2_loss = loss_fn(q2_values, q_targets)\n",
    "            critic_2_optimizer.zero_grad()\n",
    "            critic_2_loss.backward()\n",
    "            critic_2_optimizer.step()\n",
    "\n",
    "            # Update Actor network\n",
    "            if i % policy_freq == 0:\n",
    "                actor_loss = -critic_1(states, actor(states)).mean()\n",
    "                actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                actor_optimizer.step()\n",
    "\n",
    "                # Soft update target networks\n",
    "                soft_update(target_actor, actor, tau)\n",
    "                soft_update(target_critic_1, critic_1, tau)\n",
    "                soft_update(target_critic_2, critic_2, tau)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Testing\n",
    "print(\"Starting testing...\")\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input (as per template)\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using TD3\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nPredictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
