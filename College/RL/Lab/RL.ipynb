{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c52941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from termcolor import colored\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Preprocessing steps (retaining loan_status but not using it until the last part)\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Keep the 'loan_status' column for later comparison\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Discretize loan_amount (actions) into bins (for Q-Learning)\n",
    "n_actions = 10  # Define the number of discrete actions (loan amount bins)\n",
    "loan_amount_bins = np.linspace(min(y_train), max(y_train), n_actions + 1)\n",
    "y_train_discretized = (\n",
    "    np.digitize(y_train, loan_amount_bins) - 1\n",
    ")  # Discretize the loan amount\n",
    "\n",
    "# Initialize Q-table (states = feature combinations, actions = discretized loan amounts)\n",
    "n_states = X_train.shape[1]\n",
    "Q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "# Q-learning parameters\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.9  # Discount factor\n",
    "epsilon = 0.3  # Exploration-exploitation tradeoff\n",
    "n_episodes = 100  # Number of episodes\n",
    "\n",
    "# Q-learning algorithm\n",
    "for episode in range(n_episodes):\n",
    "    for i, state in enumerate(X_train):  # Loop through each data point as a state\n",
    "        if np.random.uniform(0, 1) < epsilon:  # Exploration\n",
    "            action = np.random.randint(0, n_actions)\n",
    "        else:  # Exploitation\n",
    "            state_index = np.digitize(state, bins=np.linspace(-3, 3, n_states)) - 1\n",
    "            action = np.argmax(Q_table[state_index])\n",
    "\n",
    "        # Find the next state and reward (predicted loan amount vs actual)\n",
    "        reward = -np.abs(\n",
    "            loan_amount_bins[action] - y_train.iloc[i]\n",
    "        )  # Reward is negative error\n",
    "\n",
    "        # Update Q-value using the Q-learning update rule\n",
    "        next_state = X_train[i]\n",
    "        Q_table[:, action] = Q_table[:, action] + alpha * (\n",
    "            reward + gamma * np.max(Q_table[:, action]) - Q_table[:, action]\n",
    "        )\n",
    "\n",
    "# Testing\n",
    "y_pred_discretized = []\n",
    "for state in X_test:\n",
    "    action = np.argmax(Q_table[:, np.random.randint(0, n_states)])\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_pred_discretized.append(predicted_loan_amount)\n",
    "\n",
    "# Inverse scaling the predicted values\n",
    "y_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input (as per template)\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using Q-learning\n",
    "y_custom_pred_discretized = []\n",
    "for state in X_custom:\n",
    "    action = np.argmax(Q_table[:, np.random.randint(0, n_states)])\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_custom_pred_discretized.append(predicted_loan_amount)\n",
    "\n",
    "# Inverse scaling custom predictions\n",
    "y_custom_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_custom_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom}\")\n",
    "\n",
    "# Loan approval predictions for custom input\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status for evaluation\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Parameters for DDPG\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = 1  # Continuous output (loan amount prediction)\n",
    "learning_rate_actor = 0.001\n",
    "learning_rate_critic = 0.001\n",
    "gamma = 0.99  # Discount factor\n",
    "tau = 0.001  # For soft target updates\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Define Actor and Critic networks\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + action_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        a = (\n",
    "            a if a.dim() == 2 else a.unsqueeze(1)\n",
    "        )  # Ensure action tensor has correct dimensions\n",
    "        x = torch.cat([x, a], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Initialize Actor, Critic, and their target networks\n",
    "actor = ActorNetwork(input_size, output_size)\n",
    "target_actor = ActorNetwork(input_size, output_size)\n",
    "critic = CriticNetwork(input_size, output_size)\n",
    "target_critic = CriticNetwork(input_size, output_size)\n",
    "\n",
    "# Copy weights from the original networks to the target networks\n",
    "target_actor.load_state_dict(actor.state_dict())\n",
    "target_critic.load_state_dict(critic.state_dict())\n",
    "\n",
    "# Optimizers\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate_actor)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=learning_rate_critic)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Soft update target networks\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, source_param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            tau * source_param.data + (1.0 - tau) * target_param.data\n",
    "        )\n",
    "\n",
    "\n",
    "# Train the DDPG model\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    for i, state in enumerate(X_train):\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action = actor(state_tensor).detach().numpy().flatten()\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(y_train_scaled[i] - action[0])  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(np.array(states))\n",
    "            actions = (\n",
    "                torch.FloatTensor(np.array(actions)).unsqueeze(1)\n",
    "                if actions[0].ndim == 0\n",
    "                else torch.FloatTensor(np.array(actions))\n",
    "            )\n",
    "            rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "            next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "            # Compute target Q-values\n",
    "            next_actions = target_actor(next_states)\n",
    "            target_q_values = target_critic(next_states, next_actions).detach()\n",
    "            q_targets = rewards + (gamma * target_q_values)\n",
    "\n",
    "            # Compute predicted Q-values and update Critic network\n",
    "            q_values = critic(states, actions)\n",
    "            critic_loss = loss_fn(q_values, q_targets)\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            # Update Actor network\n",
    "            actor_loss = -critic(states, actor(states)).mean()\n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "\n",
    "            # Soft update target networks\n",
    "            soft_update(target_actor, actor, tau)\n",
    "            soft_update(target_critic, critic, tau)\n",
    "\n",
    "# Testing\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using DDPG\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34147591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status for evaluation\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Parameters for C51\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 51  # Number of atoms in C51\n",
    "learning_rate = 0.001\n",
    "gamma = 0.99\n",
    "v_min = -10\n",
    "v_max = 10\n",
    "n_atoms = 51\n",
    "delta_z = (v_max - v_min) / (n_atoms - 1)\n",
    "z = torch.linspace(v_min, v_max, n_atoms)\n",
    "\n",
    "\n",
    "# Define the C51 Network\n",
    "class C51Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(C51Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.output_layer = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        logits = self.output_layer(x)\n",
    "        return torch.softmax(logits.view(-1, n_atoms), dim=1)\n",
    "\n",
    "\n",
    "# Initialize network\n",
    "c51_network = C51Network(input_size, output_size)\n",
    "optimizer = optim.Adam(c51_network.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the C51 model\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    for i in range(len(X_train)):\n",
    "        state = torch.FloatTensor(X_train[i]).unsqueeze(0)\n",
    "        target_distribution = torch.zeros((1, n_atoms))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mean = y_train_scaled[i]\n",
    "            b = torch.tensor((mean - v_min) / delta_z)\n",
    "            l = int(torch.floor(b).item())\n",
    "            u = int(torch.ceil(b).item())\n",
    "\n",
    "            target_distribution[0, l] += u - b\n",
    "            if u < n_atoms:\n",
    "                target_distribution[0, u] += b - l\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_distribution = c51_network(state)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = -(target_distribution * torch.log(predicted_distribution)).sum()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    predicted_distribution = c51_network(state_tensor)\n",
    "    expected_value = torch.sum(predicted_distribution * z, dim=1).item()\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[expected_value]])[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using C51\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    predicted_distribution = c51_network(state_tensor)\n",
    "    expected_value = torch.sum(predicted_distribution * z, dim=1).item()\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[expected_value]])[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(f\"Test Case {i+1}: Loan will be approved\")\n",
    "    else:\n",
    "        print(f\"Test Case {i+1}: Loan will not be approved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37964bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status for evaluation\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Parameters for DDPG\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = 1  # Continuous output (loan amount prediction)\n",
    "learning_rate_actor = 0.001\n",
    "learning_rate_critic = 0.001\n",
    "gamma = 0.99  # Discount factor\n",
    "tau = 0.001  # For soft target updates\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Define Actor and Critic networks\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + action_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        a = (\n",
    "            a if a.dim() == 2 else a.unsqueeze(1)\n",
    "        )  # Ensure action tensor has correct dimensions\n",
    "        x = torch.cat([x, a], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Initialize Actor, Critic, and their target networks\n",
    "actor = ActorNetwork(input_size, output_size)\n",
    "target_actor = ActorNetwork(input_size, output_size)\n",
    "critic = CriticNetwork(input_size, output_size)\n",
    "target_critic = CriticNetwork(input_size, output_size)\n",
    "\n",
    "# Copy weights from the original networks to the target networks\n",
    "target_actor.load_state_dict(actor.state_dict())\n",
    "target_critic.load_state_dict(critic.state_dict())\n",
    "\n",
    "# Optimizers\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate_actor)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=learning_rate_critic)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Soft update target networks\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, source_param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            tau * source_param.data + (1.0 - tau) * target_param.data\n",
    "        )\n",
    "\n",
    "\n",
    "# Train the DDPG model\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    for i, state in enumerate(X_train):\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action = actor(state_tensor).detach().numpy().flatten()\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(y_train_scaled[i] - action[0])  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(np.array(states))\n",
    "            actions = (\n",
    "                torch.FloatTensor(np.array(actions)).unsqueeze(1)\n",
    "                if actions[0].ndim == 0\n",
    "                else torch.FloatTensor(np.array(actions))\n",
    "            )\n",
    "            rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "            next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "            # Compute target Q-values\n",
    "            next_actions = target_actor(next_states)\n",
    "            target_q_values = target_critic(next_states, next_actions).detach()\n",
    "            q_targets = rewards + (gamma * target_q_values)\n",
    "\n",
    "            # Compute predicted Q-values and update Critic network\n",
    "            q_values = critic(states, actions)\n",
    "            critic_loss = loss_fn(q_values, q_targets)\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            # Update Actor network\n",
    "            actor_loss = -critic(states, actor(states)).mean()\n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "\n",
    "            # Soft update target networks\n",
    "            soft_update(target_actor, actor, tau)\n",
    "            soft_update(target_critic, critic, tau)\n",
    "\n",
    "# Testing\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using DDPG\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status for evaluation\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Discretize loan_amount (actions) into bins (for DQN)\n",
    "n_actions = 10  # Define the number of discrete actions (loan amount bins)\n",
    "loan_amount_bins = np.linspace(min(y_train), max(y_train), n_actions + 1)\n",
    "y_train_discretized = (\n",
    "    np.digitize(y_train, loan_amount_bins) - 1\n",
    ")  # Discretize the loan amount\n",
    "\n",
    "\n",
    "# Define the Deep Q-Network (DQN) architecture\n",
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Parameters for DQN\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = n_actions  # Number of actions (discretized loan amounts)\n",
    "learning_rate = 0.001\n",
    "gamma = 0.9  # Discount factor\n",
    "epsilon = 1.0  # Exploration-exploitation tradeoff\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "target_update_frequency = 10  # Frequency of updating the target network\n",
    "\n",
    "# Initialize the DQN model and optimizer\n",
    "model = DQNetwork(input_size, output_size)\n",
    "target_model = DQNetwork(input_size, output_size)\n",
    "target_model.load_state_dict(model.state_dict())  # Copy the weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Epsilon-greedy action selection\n",
    "def select_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(0, n_actions)  # Exploration\n",
    "    else:\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = model(state_tensor)\n",
    "        return torch.argmax(q_values).item()  # Exploitation\n",
    "\n",
    "\n",
    "# Update the target network\n",
    "def update_target_network():\n",
    "    target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "# Train the DQN\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    for i, state in enumerate(X_train):\n",
    "        action = select_action(state, epsilon)\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(\n",
    "            loan_amount_bins[action] - y_train.iloc[i]\n",
    "        )  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(states)\n",
    "            actions = torch.LongTensor(actions)\n",
    "            rewards = torch.FloatTensor(rewards)\n",
    "            next_states = torch.FloatTensor(next_states)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            q_targets_next = target_model(next_states).max(1)[0].detach()\n",
    "            q_targets = rewards + (gamma * q_targets_next)\n",
    "\n",
    "            # Compute predicted Q-values\n",
    "            q_values = model(states)\n",
    "            q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze()\n",
    "\n",
    "            # Compute loss and update the model\n",
    "            loss = loss_fn(q_values, q_targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Update the target network\n",
    "    if episode % target_update_frequency == 0:\n",
    "        update_target_network()\n",
    "\n",
    "    # Decay epsilon (reduce exploration)\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "# Testing\n",
    "y_pred_discretized = []\n",
    "for state in X_test:\n",
    "    action = select_action(state, epsilon=0.0)  # Pure exploitation\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_pred_discretized.append(predicted_loan_amount)\n",
    "\n",
    "# Inverse scaling the predicted values\n",
    "y_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using DQN\n",
    "y_custom_pred_discretized = []\n",
    "for state in X_custom:\n",
    "    action = select_action(state, epsilon=0.0)  # Pure exploitation\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_custom_pred_discretized.append(predicted_loan_amount)\n",
    "\n",
    "# Inverse scaling custom predictions\n",
    "y_custom_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_custom_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51442705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Parameters for PPO\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "gamma = 0.99\n",
    "eps_clip = 0.2\n",
    "k_epochs = 10\n",
    "n_episodes = 5\n",
    "\n",
    "\n",
    "# Define the Policy Network\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.mean_layer = nn.Linear(128, output_size)\n",
    "        self.log_std = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        mean = self.mean_layer(x)\n",
    "        std = torch.exp(self.log_std)\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "# Define the Value Network\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.value_layer = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        value = self.value_layer(x)\n",
    "        return value\n",
    "\n",
    "\n",
    "# Initialize networks\n",
    "policy_network = PolicyNetwork(input_size, output_size)\n",
    "value_network = ValueNetwork(input_size)\n",
    "policy_optimizer = optim.Adam(policy_network.parameters(), lr=learning_rate)\n",
    "value_optimizer = optim.Adam(value_network.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Compute PPO loss\n",
    "def ppo_loss(old_log_probs, new_log_probs, advantages, eps_clip):\n",
    "    ratio = torch.exp(new_log_probs - old_log_probs)\n",
    "    surr1 = ratio * advantages\n",
    "    surr2 = torch.clamp(ratio, 1 - eps_clip, 1 + eps_clip) * advantages\n",
    "    return -torch.min(surr1, surr2).mean()\n",
    "\n",
    "\n",
    "# Train the PPO model\n",
    "for episode in range(n_episodes):\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "\n",
    "    # Collect trajectories\n",
    "    for i in range(len(X_train)):\n",
    "        state = torch.FloatTensor(X_train[i]).unsqueeze(0)\n",
    "        mean, std = policy_network(state)\n",
    "        dist = MultivariateNormal(mean, torch.diag(std + 1e-6))\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        reward = -np.abs(y_train_scaled[i] - action.item())  # Reward is negative error\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "\n",
    "    # Compute value targets\n",
    "    values = torch.cat([value_network(state) for state in states])\n",
    "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "    advantages = rewards - values.detach()\n",
    "\n",
    "    # Update value network\n",
    "    value_loss = torch.mean((values - rewards) ** 2)\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward(retain_graph=True)\n",
    "    value_optimizer.step()\n",
    "\n",
    "    # Update policy network using PPO\n",
    "    old_log_probs = torch.cat(log_probs).detach()\n",
    "    for _ in range(k_epochs):\n",
    "        new_log_probs = torch.cat(\n",
    "            [\n",
    "                MultivariateNormal(\n",
    "                    policy_network(state)[0],\n",
    "                    torch.diag(torch.exp(policy_network(state)[1]) + 1e-6),\n",
    "                ).log_prob(action)\n",
    "                for state, action in zip(states, actions)\n",
    "            ]\n",
    "        )\n",
    "        loss = ppo_loss(old_log_probs, new_log_probs, advantages, eps_clip)\n",
    "\n",
    "        policy_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        policy_optimizer.step()\n",
    "\n",
    "# Testing\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    mean, _ = policy_network(state_tensor)\n",
    "    predicted_loan_amount = y_scaler.inverse_transform(mean.detach().numpy())[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test.apply(lambda x: \"Approved\" if x >= 0 else \"Rejected\"), y_pred_loan_status\n",
    "    )\n",
    ")\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using PPO\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    mean, _ = policy_network(state_tensor)\n",
    "    predicted_loan_amount = y_scaler.inverse_transform(mean.detach().numpy())[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nPredictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(f\"Test Case {i+1}: Loan will be approved\")\n",
    "    else:\n",
    "        print(f\"Test Case {i+1}: Loan will not be approved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f89a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status for evaluation\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Parameters for QR-DQN\n",
    "input_size = X_train.shape[1]\n",
    "n_quantiles = 51\n",
    "learning_rate = 0.001\n",
    "gamma = 0.99\n",
    "tau = torch.linspace(0.0, 1.0, n_quantiles + 1)[1:]  # Quantiles to estimate\n",
    "\n",
    "\n",
    "# Define the QR-DQN Network\n",
    "class QRDQNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, n_quantiles):\n",
    "        super(QRDQNNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.output_layer = nn.Linear(128, n_quantiles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        quantiles = self.output_layer(x)\n",
    "        return quantiles\n",
    "\n",
    "\n",
    "# Initialize network\n",
    "qr_dqn_network = QRDQNNetwork(input_size, n_quantiles)\n",
    "optimizer = optim.Adam(qr_dqn_network.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the QR-DQN model\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    for i in range(len(X_train)):\n",
    "        state = torch.FloatTensor(X_train[i]).unsqueeze(0)\n",
    "        target_quantiles = torch.zeros((1, n_quantiles))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target = y_train_scaled[i]\n",
    "            td_error = target - qr_dqn_network(state)\n",
    "            target_quantiles = td_error * (tau - (td_error < 0).float())\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_quantiles = qr_dqn_network(state)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = torch.mean(target_quantiles * predicted_quantiles)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    predicted_quantiles = qr_dqn_network(state_tensor)\n",
    "    expected_value = torch.mean(predicted_quantiles).item()\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[expected_value]])[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using QR-DQN\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    predicted_quantiles = qr_dqn_network(state_tensor)\n",
    "    expected_value = torch.mean(predicted_quantiles).item()\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[expected_value]])[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(f\"Test Case {i+1}: Loan will be approved\")\n",
    "    else:\n",
    "        print(f\"Test Case {i+1}: Loan will not be approved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps (from your template)\n",
    "print(\"Reading dataset...\")\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "print(\"Dataset read successfully.\")\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "print(\"Label encoding columns...\")\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "print(\"Label encoding completed.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "print(\"Separating features and target variable...\")\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "print(\"Features and target separated.\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"Feature standardization completed.\")\n",
    "\n",
    "# Scale the target variable as well\n",
    "print(\"Scaling target variable...\")\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "print(\"Target scaling completed.\")\n",
    "\n",
    "# Discretize loan_amount (actions) into bins (for SARSA)\n",
    "print(\"Discretizing loan amounts...\")\n",
    "n_actions = 10  # Define the number of discrete actions (loan amount bins)\n",
    "loan_amount_bins = np.linspace(min(y_train), max(y_train), n_actions + 1)\n",
    "y_train_discretized = (\n",
    "    np.digitize(y_train, loan_amount_bins) - 1\n",
    ")  # Discretize the loan amount\n",
    "print(\"Loan amount discretization completed.\")\n",
    "\n",
    "\n",
    "# Define the SARSA Network architecture\n",
    "class SARSANetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SARSANetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Parameters for SARSA\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = n_actions  # Number of actions (discretized loan amounts)\n",
    "learning_rate = 0.001\n",
    "gamma = 0.9  # Discount factor\n",
    "epsilon = 1.0  # Exploration-exploitation tradeoff\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "\n",
    "# Initialize the SARSA model and optimizer\n",
    "print(\"Initializing SARSA model and optimizer...\")\n",
    "model = SARSANetwork(input_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "print(\"Model and optimizer initialized.\")\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Epsilon-greedy action selection\n",
    "def select_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = np.random.randint(0, n_actions)  # Exploration\n",
    "    else:\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = model(state_tensor)\n",
    "        action = torch.argmax(q_values).item()  # Exploitation\n",
    "    return action\n",
    "\n",
    "\n",
    "# Train the SARSA model\n",
    "print(\"Starting training...\")\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    print(f\"Episode {episode + 1}/{n_episodes}\")\n",
    "    for i, state in enumerate(X_train):\n",
    "        action = select_action(state, epsilon)\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(\n",
    "            loan_amount_bins[action] - y_train.iloc[i]\n",
    "        )  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(np.array(states))\n",
    "            actions = torch.LongTensor(actions)\n",
    "            rewards = torch.FloatTensor(rewards)\n",
    "            next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "            # Compute target Q-values\n",
    "            q_targets_next = model(next_states).max(1)[0].detach()\n",
    "            q_targets = rewards + (gamma * q_targets_next)\n",
    "\n",
    "            # Compute predicted Q-values\n",
    "            q_values = model(states)\n",
    "            q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze()\n",
    "\n",
    "            # Compute loss and update the model\n",
    "            loss = loss_fn(q_values, q_targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decay epsilon (reduce exploration)\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "    print(f\"Epsilon after episode {episode + 1}: {epsilon}\")\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Testing\n",
    "print(\"Starting testing...\")\n",
    "y_pred_discretized = []\n",
    "for state in X_test:\n",
    "    action = select_action(state, epsilon=0.0)  # Pure exploitation\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_pred_discretized.append(predicted_loan_amount)\n",
    "    print(f\"Test state: Predicted discretized loan amount: {predicted_loan_amount}\")\n",
    "\n",
    "# Inverse scaling the predicted values\n",
    "y_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "print(\"Testing completed. Predicted loan amounts:\")\n",
    "print(y_pred)\n",
    "\n",
    "# Testing on custom input (as per template)\n",
    "print(\"Testing on custom input...\")\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "print(\"Preprocessing custom input...\")\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "print(\"Custom input preprocessing completed.\")\n",
    "\n",
    "# Predicting using SARSA\n",
    "print(\"Predicting on custom input...\")\n",
    "y_custom_pred_discretized = []\n",
    "for state in X_custom:\n",
    "    action = select_action(state, epsilon=0.0)  # Pure exploitation\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_custom_pred_discretized.append(predicted_loan_amount)\n",
    "    print(f\"Custom state: Predicted discretized loan amount: {predicted_loan_amount}\")\n",
    "\n",
    "# Inverse scaling custom predictions\n",
    "y_custom_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_custom_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nPredictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status for evaluation\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Discretize loan_amount (actions) into bins (for SARSA)\n",
    "n_actions = 10  # Define the number of discrete actions (loan amount bins)\n",
    "loan_amount_bins = np.linspace(min(y_train), max(y_train), n_actions + 1)\n",
    "y_train_discretized = (\n",
    "    np.digitize(y_train, loan_amount_bins) - 1\n",
    ")  # Discretize the loan amount\n",
    "\n",
    "\n",
    "# Define the SARSA Network architecture\n",
    "class SARSANetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SARSANetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Parameters for SARSA\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = n_actions  # Number of actions (discretized loan amounts)\n",
    "learning_rate = 0.001\n",
    "gamma = 0.9  # Discount factor\n",
    "epsilon = 1.0  # Exploration-exploitation tradeoff\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "\n",
    "# Initialize the SARSA model and optimizer\n",
    "model = SARSANetwork(input_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Epsilon-greedy action selection\n",
    "def select_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = np.random.randint(0, n_actions)  # Exploration\n",
    "    else:\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = model(state_tensor)\n",
    "        action = torch.argmax(q_values).item()  # Exploitation\n",
    "    return action\n",
    "\n",
    "\n",
    "# Train the SARSA model\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    for i, state in enumerate(X_train):\n",
    "        action = select_action(state, epsilon)\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(\n",
    "            loan_amount_bins[action] - y_train.iloc[i]\n",
    "        )  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(np.array(states))\n",
    "            actions = torch.LongTensor(actions)\n",
    "            rewards = torch.FloatTensor(rewards)\n",
    "            next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "            # Compute target Q-values\n",
    "            q_targets_next = model(next_states).max(1)[0].detach()\n",
    "            q_targets = rewards + (gamma * q_targets_next)\n",
    "\n",
    "            # Compute predicted Q-values\n",
    "            q_values = model(states)\n",
    "            q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze()\n",
    "\n",
    "            # Compute loss and update the model\n",
    "            loss = loss_fn(q_values, q_targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decay epsilon (reduce exploration)\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "# Testing\n",
    "y_pred_discretized = []\n",
    "for state in X_test:\n",
    "    action = select_action(state, epsilon=0.0)  # Pure exploitation\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_pred_discretized.append(predicted_loan_amount)\n",
    "\n",
    "# Inverse scaling the predicted values\n",
    "y_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using SARSA\n",
    "y_custom_pred_discretized = []\n",
    "for state in X_custom:\n",
    "    action = select_action(state, epsilon=0.0)  # Pure exploitation\n",
    "    predicted_loan_amount = loan_amount_bins[action]\n",
    "    y_custom_pred_discretized.append(predicted_loan_amount)\n",
    "\n",
    "# Inverse scaling custom predictions\n",
    "y_custom_pred = y_scaler.inverse_transform(\n",
    "    np.array(y_custom_pred_discretized).reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nLoan Approval Predictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from collections import deque\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps (from your template)\n",
    "print(\"Reading dataset...\")\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status before dropping\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Scale the target variable as well\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Parameters for TD3\n",
    "input_size = X_train.shape[1]  # Number of features (states)\n",
    "output_size = 1  # Continuous output (loan amount prediction)\n",
    "learning_rate_actor = 0.001\n",
    "learning_rate_critic = 0.001\n",
    "gamma = 0.99  # Discount factor\n",
    "tau = 0.005  # For soft target updates\n",
    "batch_size = 64\n",
    "memory_size = 10000\n",
    "policy_noise = 0.2\n",
    "noise_clip = 0.5\n",
    "policy_freq = 2\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=memory_size)\n",
    "\n",
    "\n",
    "# Define Actor and Critic networks\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + action_size, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        a = (\n",
    "            a if a.dim() == 2 else a.unsqueeze(1)\n",
    "        )  # Ensure action tensor has correct dimensions\n",
    "        x = torch.cat([x, a], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# Initialize Actor, Critic, and their target networks\n",
    "\n",
    "actor = ActorNetwork(input_size, output_size)\n",
    "target_actor = ActorNetwork(input_size, output_size)\n",
    "critic_1 = CriticNetwork(input_size, output_size)\n",
    "target_critic_1 = CriticNetwork(input_size, output_size)\n",
    "critic_2 = CriticNetwork(input_size, output_size)\n",
    "target_critic_2 = CriticNetwork(input_size, output_size)\n",
    "\n",
    "# Copy weights from the original networks to the target networks\n",
    "target_actor.load_state_dict(actor.state_dict())\n",
    "target_critic_1.load_state_dict(critic_1.state_dict())\n",
    "target_critic_2.load_state_dict(critic_2.state_dict())\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate_actor)\n",
    "critic_1_optimizer = optim.Adam(critic_1.parameters(), lr=learning_rate_critic)\n",
    "critic_2_optimizer = optim.Adam(critic_2.parameters(), lr=learning_rate_critic)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Store experiences in the replay buffer\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "# Sample a batch of experiences\n",
    "def sample_experiences(batch_size):\n",
    "    return random.sample(memory, batch_size)\n",
    "\n",
    "\n",
    "# Soft update target networks\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, source_param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            tau * source_param.data + (1.0 - tau) * target_param.data\n",
    "        )\n",
    "\n",
    "\n",
    "# Train the TD3 model\n",
    "print(\"Starting training...\")\n",
    "n_episodes = 5\n",
    "for episode in range(n_episodes):\n",
    "    print(f\"Episode {episode + 1}/{n_episodes}\")\n",
    "    for i, state in enumerate(X_train):\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action = actor(state_tensor).detach().numpy().flatten()\n",
    "        next_state = X_train[i]\n",
    "        reward = -np.abs(y_train_scaled[i] - action[0])  # Reward is negative error\n",
    "\n",
    "        # Store experience in the replay buffer\n",
    "        store_experience(state, action, reward, next_state, False)\n",
    "\n",
    "        # Sample a batch of experiences from the memory\n",
    "        if len(memory) > batch_size:\n",
    "            experiences = sample_experiences(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "            states = torch.FloatTensor(np.array(states))\n",
    "            actions = (\n",
    "                torch.FloatTensor(np.array(actions)).unsqueeze(1)\n",
    "                if actions[0].ndim == 0\n",
    "                else torch.FloatTensor(np.array(actions))\n",
    "            )\n",
    "            rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "            next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "            # Add noise to target actions\n",
    "            noise = torch.clamp(\n",
    "                torch.normal(0, policy_noise, size=actions.shape),\n",
    "                -noise_clip,\n",
    "                noise_clip,\n",
    "            )\n",
    "            next_actions = target_actor(next_states) + noise\n",
    "            next_actions = torch.clamp(next_actions, -1, 1)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            target_q1_values = target_critic_1(next_states, next_actions).detach()\n",
    "            target_q2_values = target_critic_2(next_states, next_actions).detach()\n",
    "            q_targets = rewards + (\n",
    "                gamma * torch.min(target_q1_values, target_q2_values)\n",
    "            )\n",
    "\n",
    "            # Compute predicted Q-values and update Critic networks\n",
    "            q1_values = critic_1(states, actions)\n",
    "            critic_1_loss = loss_fn(q1_values, q_targets)\n",
    "            critic_1_optimizer.zero_grad()\n",
    "            critic_1_loss.backward()\n",
    "            critic_1_optimizer.step()\n",
    "\n",
    "            q2_values = critic_2(states, actions)\n",
    "            critic_2_loss = loss_fn(q2_values, q_targets)\n",
    "            critic_2_optimizer.zero_grad()\n",
    "            critic_2_loss.backward()\n",
    "            critic_2_optimizer.step()\n",
    "\n",
    "            # Update Actor network\n",
    "            if i % policy_freq == 0:\n",
    "                actor_loss = -critic_1(states, actor(states)).mean()\n",
    "                actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                actor_optimizer.step()\n",
    "\n",
    "                # Soft update target networks\n",
    "                soft_update(target_actor, actor, tau)\n",
    "                soft_update(target_critic_1, critic_1, tau)\n",
    "                soft_update(target_critic_2, critic_2, tau)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Testing\n",
    "print(\"Starting testing...\")\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input (as per template)\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using TD3\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    action = actor(state_tensor).detach().numpy().flatten()[0]\n",
    "    predicted_loan_amount = y_scaler.inverse_transform([[action]])[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nPredictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7588a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.distributions import MultivariateNormal\n",
    "from termcolor import colored\n",
    "\n",
    "# Preprocessing steps (from your template)\n",
    "data = pd.read_csv(\"loan_approval_dataset.csv\")\n",
    "loan_status = data[\"loan_status\"]  # Save loan_status before dropping\n",
    "data = data.drop(columns=[\"loan_status\"], axis=1)\n",
    "\n",
    "# Label encode 'education' and 'self_employed' columns\n",
    "data[\"education\"] = data[\"education\"].map({\" Not Graduate\": 0, \" Graduate\": 1})\n",
    "data[\"self_employed\"] = data[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"loan_id\", \"loan_amount\"])\n",
    "y = data[\"loan_amount\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, loan_status_train, loan_status_test = (\n",
    "    train_test_split(X, y, loan_status, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variable as well\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Parameters for TRPO\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "max_kl_divergence = 0.01\n",
    "n_episodes = 5\n",
    "\n",
    "\n",
    "# Define the Policy Network\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.mean_layer = nn.Linear(128, output_size)\n",
    "        self.log_std = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        mean = self.mean_layer(x)\n",
    "        std = torch.exp(self.log_std)\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "# Define the Value Network\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.value_layer = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        value = self.value_layer(x)\n",
    "        return value\n",
    "\n",
    "\n",
    "# Initialize networks\n",
    "policy_network = PolicyNetwork(input_size, output_size)\n",
    "value_network = ValueNetwork(input_size)\n",
    "value_optimizer = optim.Adam(value_network.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Compute surrogate loss\n",
    "def surrogate_loss(old_log_probs, new_log_probs, advantages):\n",
    "    return torch.mean(torch.exp(new_log_probs - old_log_probs) * advantages)\n",
    "\n",
    "\n",
    "# Train the TRPO model\n",
    "for episode in range(n_episodes):\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "\n",
    "    # Collect trajectories\n",
    "    for i in range(len(X_train)):\n",
    "        state = torch.FloatTensor(X_train[i]).unsqueeze(0)\n",
    "        mean, std = policy_network(state)\n",
    "        dist = MultivariateNormal(mean, torch.diag(std))\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        reward = -np.abs(y_train_scaled[i] - action.item())  # Reward is negative error\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "\n",
    "    # Compute value targets\n",
    "    values = torch.cat([value_network(state) for state in states])\n",
    "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "    advantages = rewards - values.detach()\n",
    "\n",
    "    # Update value network\n",
    "    value_loss = torch.mean((values - rewards) ** 2)\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    # Update policy network using TRPO\n",
    "    old_log_probs = torch.cat(log_probs)\n",
    "    for _ in range(10):  # Iterate for policy optimization\n",
    "        new_log_probs = torch.cat(\n",
    "            [\n",
    "                MultivariateNormal(\n",
    "                    policy_network(state)[0],\n",
    "                    torch.diag(torch.exp(policy_network(state)[1])),\n",
    "                ).log_prob(action)\n",
    "                for state, action in zip(states, actions)\n",
    "            ]\n",
    "        )\n",
    "        loss = surrogate_loss(old_log_probs, new_log_probs, advantages)\n",
    "        kl_div = torch.mean(old_log_probs - new_log_probs).abs()\n",
    "\n",
    "        if kl_div > max_kl_divergence:\n",
    "            break\n",
    "\n",
    "        value_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        value_optimizer.step()\n",
    "\n",
    "# Testing\n",
    "y_pred = []\n",
    "for state in X_test:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    mean, _ = policy_network(state_tensor)\n",
    "    predicted_loan_amount = y_scaler.inverse_transform(mean.detach().numpy())[0][0]\n",
    "    y_pred.append(predicted_loan_amount)\n",
    "\n",
    "# Generate predicted loan status based on predicted loan amount\n",
    "y_pred_loan_status = [\n",
    "    \"Approved\" if pred >= actual else \"Rejected\" for pred, actual in zip(y_pred, y_test)\n",
    "]\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(loan_status_test, y_pred_loan_status))\n",
    "\n",
    "# Testing on custom input (as per template)\n",
    "custom_input = pd.DataFrame(\n",
    "    {\n",
    "        \"no_of_dependents\": [2, 5, 3, 0],\n",
    "        \"education\": [\" Graduate\", \" Not Graduate\", \" Graduate\", \" Graduate\"],\n",
    "        \"self_employed\": [\" No\", \" Yes\", \" No\", \" No\"],\n",
    "        \"income_annum\": [3900000, 1200000, 5000000, 300000],\n",
    "        \"loan_amount\": [12300000, 5000000, 1500000, 10000000],\n",
    "        \"loan_term\": [18, 12, 24, 18],\n",
    "        \"cibil_score\": [700, 600, 750, 800],\n",
    "        \"residential_assets_value\": [7600000, 200000, 10000000, 5000000],\n",
    "        \"commercial_assets_value\": [690000, 1000000, 500000, 3000000],\n",
    "        \"luxury_assets_value\": [1300000, 200000, 10000, 5000000],\n",
    "        \"bank_asset_value\": [2800000, 50000, 200000, 300000],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Preprocessing custom input\n",
    "custom_input[\"education\"] = custom_input[\"education\"].map(\n",
    "    {\" Not Graduate\": 0, \" Graduate\": 1}\n",
    ")\n",
    "custom_input[\"self_employed\"] = custom_input[\"self_employed\"].map({\" No\": 0, \" Yes\": 1})\n",
    "X_custom = custom_input.drop(columns=[\"loan_amount\"])\n",
    "y_custom = custom_input[\"loan_amount\"]\n",
    "X_custom = scaler.transform(X_custom)\n",
    "\n",
    "# Predicting using TRPO\n",
    "y_custom_pred = []\n",
    "for state in X_custom:\n",
    "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "    mean, _ = policy_network(state_tensor)\n",
    "    predicted_loan_amount = y_scaler.inverse_transform(mean.detach().numpy())[0][0]\n",
    "    y_custom_pred.append(predicted_loan_amount)\n",
    "\n",
    "print(f\"\\n\\nPredicted loan amounts: \\n{y_custom_pred}\")\n",
    "print(f\"\\nActual applied loan amounts: \\n{y_custom.tolist()}\")\n",
    "\n",
    "# Loan approval predictions\n",
    "print(\"\\n\\nPredictions:\")\n",
    "for i in range(len(y_custom_pred)):\n",
    "    if y_custom_pred[i] > y_custom.iloc[i]:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will be approved\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Test Case {i+1}: Loan will not be approved\", \"red\"))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
