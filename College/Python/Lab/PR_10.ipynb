{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Algorithms in Machine Learning\n",
    "\n",
    "Regression analysis consists of a set of statistical processes that estimate the relationships among variables. It helps understand how the typical value of the dependent variable changes when any one of the independent variables varies. In machine learning, regression algorithms predict a continuous outcome variable (y) based on one or more predictor variables (x).\n",
    "\n",
    "## Common Types of Regression Algorithms\n",
    "\n",
    "### 1. Linear Regression\n",
    "\n",
    "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. It is used when the relationship between the dependent and independent variables is linear.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 2. Logistic Regression\n",
    "\n",
    "Though it's named \"regression,\" logistic regression is actually used for classification problems where the outcome is a categorical variable (binary or multi-class).\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 3. Decision Tree Regression\n",
    "\n",
    "Decision trees split the data into subsets, which further split into more subsets, making the decision a sequence of questions. This makes it a good option for non-linear data.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 4. Random Forest Regression\n",
    "\n",
    "Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 5. Support Vector Regression (SVR)\n",
    "\n",
    "Support Vector Regression is similar to SVM for classification. The model predicts a value, but the error does not exceed the threshold.\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = SVR()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 6. Gradient Boosting Regression\n",
    "\n",
    "Gradient boosting is a type of machine learning boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### 7. XGBoost\n",
    "\n",
    "XGBoost is an efficient and scalable implementation of gradient boosting. It has become incredibly popular because of its performance and speed.\n",
    "\n",
    "```python\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "These algorithms represent just a few of the many machine learning algorithms used in regression. Each has its strengths and weaknesses and may be suited to different types of data or problem domains. Understanding these algorithms and knowing when to apply each will equip you to tackle a wide array of regression problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 6891.797752808989\n",
      "R-squared (R2 ): -0.34397344448845835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a decision tree regressor object\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# Fit the regressor with training data\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 3750.300122471911\n",
      "R-squared (R2 ): 0.26865181564422547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a random forest regressor object\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "\n",
    "# Fit the regressor with the training data\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.05263157894736842\n",
      "R-squared (R2 ): 0.7827881867259447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# The target variable is more suitable for logistic regression since it's categorical\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "classifier = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "# Fit the classifier with the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -35.55025079 -243.16508959  562.76234744  305.46348218 -662.70290089\n",
      "  324.20738537   24.74879489  170.3249615   731.63743545   43.0309307 ]\n",
      "Mean squared error: 3424.26\n",
      "Coefficient of determination: 0.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a linear regression object\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regressor.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4243.422022471909\n",
      "R-squared (R2 ): 0.1724878302420758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create KNN regressor object\n",
    "regressor = KNeighborsRegressor(n_neighbors=5)  # here, 5 is the number of neighbors\n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4470.939682846807\n",
      "R-squared (R2 ): 0.12811948040601506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# It's a good practice to scale the data for SVM models\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(diabetes.data)\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create SVR object\n",
    "regressor = SVR(kernel='rbf')  # kernel can also be 'linear', 'poly', etc.\n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4071.9510461055215\n",
      "R-squared (R2 ): 0.20592648398710256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create Gradient Boosting Regressor object\n",
    "regressor = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:124.75405\ttrain-rmse:125.72972\n",
      "[1]\teval-rmse:96.98714\ttrain-rmse:95.93678\n",
      "[2]\teval-rmse:79.56656\ttrain-rmse:76.40035\n",
      "[3]\teval-rmse:70.01961\ttrain-rmse:63.83979\n",
      "[4]\teval-rmse:64.08181\ttrain-rmse:56.05293\n",
      "[5]\teval-rmse:62.62043\ttrain-rmse:50.80412\n",
      "[6]\teval-rmse:61.49554\ttrain-rmse:47.72474\n",
      "[7]\teval-rmse:61.78865\ttrain-rmse:45.38086\n",
      "[8]\teval-rmse:62.51831\ttrain-rmse:43.74025\n",
      "[9]\teval-rmse:62.43861\ttrain-rmse:42.50393\n",
      "[10]\teval-rmse:62.37349\ttrain-rmse:41.22457\n",
      "[11]\teval-rmse:62.28799\ttrain-rmse:40.64192\n",
      "[12]\teval-rmse:62.40342\ttrain-rmse:39.84432\n",
      "[13]\teval-rmse:62.46278\ttrain-rmse:39.03206\n",
      "[14]\teval-rmse:62.62018\ttrain-rmse:38.32677\n",
      "[15]\teval-rmse:63.19474\ttrain-rmse:37.73889\n",
      "[16]\teval-rmse:63.00371\ttrain-rmse:37.24875\n",
      "[17]\teval-rmse:63.29954\ttrain-rmse:36.68275\n",
      "[18]\teval-rmse:63.72195\ttrain-rmse:35.91110\n",
      "[19]\teval-rmse:63.80423\ttrain-rmse:35.67652\n",
      "[20]\teval-rmse:63.94451\ttrain-rmse:35.47408\n",
      "[21]\teval-rmse:64.22036\ttrain-rmse:35.24786\n",
      "[22]\teval-rmse:64.65215\ttrain-rmse:34.59054\n",
      "[23]\teval-rmse:64.54772\ttrain-rmse:34.29866\n",
      "[24]\teval-rmse:64.49398\ttrain-rmse:33.81683\n",
      "[25]\teval-rmse:64.41455\ttrain-rmse:33.47276\n",
      "[26]\teval-rmse:64.38479\ttrain-rmse:33.30762\n",
      "[27]\teval-rmse:64.36752\ttrain-rmse:33.18210\n",
      "[28]\teval-rmse:64.51208\ttrain-rmse:32.95136\n",
      "[29]\teval-rmse:64.50413\ttrain-rmse:32.80177\n",
      "[30]\teval-rmse:64.56561\ttrain-rmse:32.69032\n",
      "[31]\teval-rmse:64.11282\ttrain-rmse:32.19289\n",
      "[32]\teval-rmse:64.10381\ttrain-rmse:31.87899\n",
      "[33]\teval-rmse:64.66535\ttrain-rmse:31.35188\n",
      "[34]\teval-rmse:64.05249\ttrain-rmse:30.73868\n",
      "[35]\teval-rmse:64.49111\ttrain-rmse:30.10054\n",
      "[36]\teval-rmse:64.62129\ttrain-rmse:29.73208\n",
      "[37]\teval-rmse:65.24570\ttrain-rmse:29.29309\n",
      "[38]\teval-rmse:65.42075\ttrain-rmse:28.95054\n",
      "[39]\teval-rmse:65.24877\ttrain-rmse:28.79885\n",
      "[40]\teval-rmse:65.34644\ttrain-rmse:28.67444\n",
      "[41]\teval-rmse:65.51337\ttrain-rmse:28.54005\n",
      "[42]\teval-rmse:65.56194\ttrain-rmse:28.17597\n",
      "[43]\teval-rmse:65.48602\ttrain-rmse:27.70553\n",
      "[44]\teval-rmse:65.65388\ttrain-rmse:27.58791\n",
      "[45]\teval-rmse:65.54153\ttrain-rmse:27.27064\n",
      "[46]\teval-rmse:65.65069\ttrain-rmse:26.66575\n",
      "[47]\teval-rmse:65.69711\ttrain-rmse:26.25560\n",
      "[48]\teval-rmse:65.73345\ttrain-rmse:26.14692\n",
      "[49]\teval-rmse:65.79154\ttrain-rmse:25.95848\n",
      "Mean Squared Error (MSE): 4328.527010424716\n",
      "R-squared (R2 ): 0.15589145758220457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:617: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert the dataset into an optimized data structure called Dmatrix that XGBoost supports\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Specify the parameters\n",
    "params = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'objective': 'reg:squarederror',  # error evaluation for regression training\n",
    "    'eval_metric': 'rmse'  # evaluation metric for validation data\n",
    "}\n",
    "\n",
    "# Specify validation set to watch performance\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "num_round = 50  # the number of training iterations\n",
    "\n",
    "# Train the model\n",
    "bst = xgb.train(params, dtrain, num_round, watchlist)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "# Calculate and print metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
